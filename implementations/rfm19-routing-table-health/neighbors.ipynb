{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ec679ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64, os\n",
    "import multihash as mh\n",
    "import hashlib as hl  \n",
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658b949f",
   "metadata": {},
   "source": [
    "## Kademlia key implementation taken from https://github.com/libp2p/py-libp2p-xor/blob/master/key/key.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "884d7f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bits_in_byte returns a list of bits in a byte, in descending order of significance.\n",
    "def bits_in_byte(byte):\n",
    "    return [\n",
    "        byte & 0x80 != 0,\n",
    "        byte & 0x40 != 0,\n",
    "        byte & 0x20 != 0,\n",
    "        byte & 0x10 != 0,\n",
    "        byte & 0x8 != 0,\n",
    "        byte & 0x4 != 0,\n",
    "        byte & 0x2 != 0,\n",
    "        byte & 0x1 != 0,\n",
    "    ]\n",
    "\n",
    "\n",
    "class Key(bytes):\n",
    "    def bit_len(self):\n",
    "        return len(self) * 8\n",
    "\n",
    "    def bit_at(self, offset):\n",
    "        return self[offset // 8] & (1 << (7 - offset % 8))\n",
    "\n",
    "    def to_float(self):\n",
    "        f = 0.0\n",
    "        s = 1.0\n",
    "        for byte in self:\n",
    "            for bit in bits_in_byte(byte):\n",
    "                s /= 2.0\n",
    "                if bit:\n",
    "                    f += s\n",
    "        return f\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        if isinstance(other, Key):\n",
    "            return self.hex() == other.hex()\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    def __hash__(self):\n",
    "        return hash(self.hex())\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.hex()\n",
    "\n",
    "\n",
    "def choose_key(n):\n",
    "    return Key(bytearray(os.urandom(n)))\n",
    "\n",
    "\n",
    "def xor_key(x: Key, y: Key):\n",
    "    return Key(bytes([x[k] ^ y[k] for k in range(len(x))]))\n",
    "\n",
    "\n",
    "def key_from_base64_kbucket_id_optional(s: str):\n",
    "    return key_from_base64_kbucket_id(s) if s else None\n",
    "\n",
    "\n",
    "def key_from_base64_kbucket_id(s: str):\n",
    "    return Key(base64.b64decode(s))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99c13b6",
   "metadata": {},
   "source": [
    "## Useful helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c956ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bytes_to_bit_string(data: bytes) -> str:\n",
    "    return \"\".join(f'{byte:08b}' for byte in data)\n",
    "  \n",
    "def multihash_to_kad_id(peer_id: str) -> bytes:  \n",
    "    multi_hash = mh.from_b58_string(peer_id)\n",
    "    return hl.sha256(multi_hash).digest()\n",
    "# this should be a clean way (even if it could be done in less lines it is more readable)\n",
    "def xor_distance(bytes0: bytes, bytes1: bytes):\n",
    "    xor=bytearray()\n",
    "    maxlen=max(len(bytes0), len(bytes1))\n",
    "\n",
    "    for i in range(maxlen):\n",
    "        byte0 = bytes0[i if len(bytes0)>len(bytes1) else i-len(bytes1)+len(bytes0)] if i >= maxlen-len(bytes0) else 0\n",
    "        byte1 = bytes1[i if len(bytes1)>len(bytes0) else i-len(bytes0)+len(bytes1)] if i >= maxlen-len(bytes1) else 0\n",
    "        xor.append(byte0 ^ byte1)\n",
    "\n",
    "    return bytes(xor)\n",
    "\n",
    "# get the corresponding k-bucket for the given XOR distance in bytes\n",
    "def bucket_number_for_distance(d: bytes) -> int:\n",
    "    count=0\n",
    "    # iterate on the bytes from left to right\n",
    "    for b in d:\n",
    "        # while the byte==0, add 8 (bits) to the counter\n",
    "        count+=8\n",
    "        if b!=0:\n",
    "            # at the first non null byte, shift right until this byte==0\n",
    "            while b!=0:\n",
    "                b>>=1\n",
    "                # for each right shift, remove 1 to counter\n",
    "                count-=1\n",
    "            break\n",
    "    # return the length of the byte string minus the number of leading 0 bits\n",
    "    return 8*len(d)-count\n",
    "\n",
    "\n",
    "##### TESTING METHODS #####\n",
    "\n",
    "def bitstring_to_bytes(s):\n",
    "    v = int(s, 2)\n",
    "    b = bytearray()\n",
    "    while v:\n",
    "        b.append(v & 0xff)\n",
    "        v >>= 8\n",
    "    return bytes(b[::-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6fc292",
   "metadata": {},
   "source": [
    "## XOR trie implementation taken from https://github.com/libp2p/py-libp2p-xor/blob/master/trie/trie.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "409e173a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Trie1:\n",
    "    branch: (any, any)\n",
    "    key: Key\n",
    "\n",
    "    def __init__(self):\n",
    "        self.branch = (None, None)\n",
    "        self.key = None\n",
    "\n",
    "    def is_empty(self):\n",
    "        return not self.key\n",
    "\n",
    "    def is_leaf(self):\n",
    "        return not self.branch[0] and not self.branch[1]\n",
    "\n",
    "    def is_empty_leaf(self):\n",
    "        return self.is_empty() and self.is_leaf()\n",
    "\n",
    "    def is_non_empty_leaf(self):\n",
    "        return not self.is_empty() and self.is_leaf()\n",
    "\n",
    "    def size(self):\n",
    "        return self.size_at_depth(0)\n",
    "\n",
    "    def size_at_depth(self, depth):\n",
    "        if self.is_leaf():\n",
    "            return 0 if self.is_empty() else 1\n",
    "        else:\n",
    "            return self.branch[0].size_at_depth(depth + 1) + self.branch[1].size_at_depth(depth + 1)\n",
    "\n",
    "    def add(self, key):\n",
    "        return self.add_at_depth(0, key)\n",
    "\n",
    "    def add_at_depth(self, depth, key):\n",
    "        if self.is_empty_leaf():\n",
    "            self.key = key\n",
    "            return depth, True\n",
    "        elif self.is_non_empty_leaf():\n",
    "            if key == self.key:\n",
    "                # key already in trie\n",
    "                return depth, False\n",
    "            else:\n",
    "                p = self.key\n",
    "                self.key = None\n",
    "                self.branch = (Trie(), Trie())\n",
    "                self.branch[p.bit_at(depth)].key = p\n",
    "                return self.branch[key.bit_at(depth)].add_at_depth(depth + 1, key)\n",
    "        else:\n",
    "            return self.branch[key.bit_at(depth)].add_at_depth(depth + 1, key)\n",
    "\n",
    "    def remove(self, key):\n",
    "        return self.remove_at_depth(0, key)\n",
    "\n",
    "    def remove_at_depth(self, depth, key):\n",
    "        if self.is_empty_leaf():\n",
    "            return depth, False\n",
    "        elif self.is_non_empty_leaf():\n",
    "            self.key = None\n",
    "            return depth, True\n",
    "        else:\n",
    "            d, removed = self.branch[key.bit_at(depth)].remove_at_depth(depth + 1, key)\n",
    "            if removed:\n",
    "                self.shrink()\n",
    "                return d, True\n",
    "            else:\n",
    "                return d, False\n",
    "\n",
    "    def find(self, key):\n",
    "        return self.find_at_depth(0, key)\n",
    "\n",
    "    def find_at_depth(self, depth, key):\n",
    "        if self.is_empty_leaf():\n",
    "            return None, depth\n",
    "        elif self.is_non_empty_leaf():\n",
    "            return self.key, depth\n",
    "        else:\n",
    "            return self.branch[key.bit_at(depth)].find_at_depth(depth + 1, key)\n",
    "\n",
    "    def list_of_depths(self):\n",
    "        return self.list_of_depths_at_depth(0)\n",
    "\n",
    "    def list_of_depths_at_depth(self, depth):\n",
    "        if self.is_empty_leaf():\n",
    "            return []\n",
    "        elif self.is_non_empty_leaf():\n",
    "            return [depth]\n",
    "        else:\n",
    "            l0 = self.branch[0].list_of_depths_at_depth(depth + 1)\n",
    "            l1 = self.branch[1].list_of_depths_at_depth(depth + 1)\n",
    "            return l0 + l1\n",
    "\n",
    "    def shrink(self):\n",
    "        b0, b1 = self.branch[0], self.branch[1]\n",
    "        if b0.is_empty_leaf() and b1.is_empty_leaf():\n",
    "            self.branch = (None, None)\n",
    "        elif b0.is_empty_leaf() and b1.is_non_empty_leaf():\n",
    "            self.key = b1.key\n",
    "            self.branch = (None, None)\n",
    "        elif b0.is_non_empty_leaf() and b1.is_empty_leaf():\n",
    "            self.key = b0.key\n",
    "            self.branch = (None, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e4bc53",
   "metadata": {},
   "source": [
    "## Peer class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1a59e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Peer(object):\n",
    "\n",
    "    def __init__(self, index, key, neighbors, buckets, alive):\n",
    "        self.index = index # not necessary, but convienient to work with Nebula Crawler\n",
    "        self.key = key\n",
    "        # neighbors ordered from closer to farthest\n",
    "        # TODO: or the other way round?\n",
    "        self.neighbors = neighbors\n",
    "        # bucket 0 contains the farthest peers (full), high buckets are empty\n",
    "        # TODO: dictionary?\n",
    "        self.buckets = buckets\n",
    "        self.alive = alive\n",
    "                \n",
    "    def distance(self, p):\n",
    "        return xor_key(self.key, p.key)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde1e7a3",
   "metadata": {},
   "source": [
    "## Nebula Crawler database queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d60b54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "\n",
    "# query to connect to the postgresql db\n",
    "postgres_connect_query=\"host=127.0.0.1 dbname=nebula user=nebula password=password\"\n",
    "# query to get all peers\n",
    "get_peers_query=\"select id,multi_hash from peers;\"\n",
    "# query to retrieve all neighbors relations between peers\n",
    "get_neighbors_query=\"select peer_id,neighbor_ids from neighbors where crawl_id=2;\"\n",
    "\n",
    "# indexes in the postgresql peers/neighbors db for multihashes and ids (topo id)\n",
    "peers_id_col=0       # for both peers and neighbors query results\n",
    "peers_mh_col=1       # for peers query results\n",
    "neighbor_ids_col=1   # for neighbors query results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846bbadc",
   "metadata": {},
   "source": [
    "## Query the Nebula DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "172b21f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup connection to postgresql db\n",
    "conn = psycopg2.connect(postgres_connect_query)\n",
    "cur = conn.cursor()\n",
    "\n",
    "# query peers nebulaID and peerID\n",
    "cur.execute(get_peers_query)\n",
    "#peer_list = {l[peers_id_col]: [multihash_to_kad_id(l[peers_mh_col]), l[peers_mh_col]] for l in cur.fetchall()}\n",
    "peer_list = {l[peers_id_col]: l[peers_mh_col] for l in cur.fetchall()}\n",
    "\n",
    "# query relations between peers (which peer is in which peer's routing table)\n",
    "cur.execute(get_neighbors_query)\n",
    "neighbors_relations = {node:neighbors for (node, neighbors) in cur.fetchall()}\n",
    "\n",
    "# line format: nebula_id, peer_id, neighbor_1_nebula_id, neighbor_2_nebula_id, ... neighbor_n_nebula_id\n",
    "# if no neighbor: nebula_id, peer_id\n",
    "nebula_peers = [[i, peer_list[i]] + (neighbors_relations[i] if i in neighbors_relations else []) for i in peer_list]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d212382",
   "metadata": {},
   "source": [
    "## Save data to disk to access it without having to start Nebula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "19912328",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "filename = \"nebula-peers.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e3dbfc76",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(filename, 'w') as file:\n",
    "    csvwriter = csv.writer(file)\n",
    "    csvwriter.writerows(nebula_peers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4b8ff8e4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open(filename, 'r') as file:\n",
    "    nebula_peers = [line for line in csv.reader(file)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b526c8f",
   "metadata": {},
   "source": [
    "## Build the trie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e2b92f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NebulaPeer:\n",
    "    def __init__(self, nebula_id, peer_id, neighbors):\n",
    "        self.nebula_id = nebula_id\n",
    "        self.peer_id = peer_id\n",
    "        self.neighbors = neighbors\n",
    "        \n",
    "        self.key = Key(multihash_to_kad_id(peer_id))\n",
    "        \n",
    "    def __str__(self):\n",
    "        return \"nebula_id: \"+str(self.nebula_id)+\", peer_id: \"+str(self.peer_id)+\", neighbors: \"+str(self.neighbors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "aa072ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "peers = [NebulaPeer(line[0], line[1], line[2:]) for line in nebula_peers]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82cb45a",
   "metadata": {},
   "source": [
    "# Defining a new Trie\n",
    "\n",
    "Each node has references to 0 or 2 children and 1 parent. It contains its own key, size, (depth,) and reference to Peer object (containing the list of neighbors) for leaves.\n",
    "\n",
    "The difference with the above python implementation, is that is supports depth skips, doesn't rely on depth, has bottom up references (2 way parent-children link), and points to an Object.\n",
    "\n",
    "## Attributes\n",
    "## parent\n",
    "pointer to parent node: TrieNode\n",
    "## children\n",
    "pointers to 2 children (any,any)\n",
    "for non-leaves only\n",
    "## size\n",
    "size(children_0)+size(children_1)\n",
    "## peer\n",
    "pointer to peer (for leaves only)\n",
    "## key\n",
    "key identifying the TrieNode\n",
    "\n",
    "## Functions\n",
    "### add(key,node)\n",
    "adds a node to the trie. from the root, go down the trie until we don't match anymore. If the direction has already a link, it's a skip -> create a fork at the appropriate level between the next hop and the node. Else, add a link to the newly created node\n",
    "### size()\n",
    "returns the number of leaves in the (sub-)trie\n",
    "the size comptutation takes O(n)\n",
    "this should be an attribute and not a method\n",
    "### find(key)\n",
    "return True if key in trie\n",
    "\n",
    "### closestN(key,n)\n",
    "returns the n closest keys/TrieNode to given key\n",
    "\n",
    "### intersection(trie)\n",
    "to check intersection between global trie and local peer knowledge trie\n",
    "maybe not very useful after all. global trie has all knowledge from local nodes by definition by Nebula crawler\n",
    "### union(trie)\n",
    "similar to interesection\n",
    "\n",
    "# Peer\n",
    "A node object should know (its depth in Trie), its neighbors (possibly ranked from closest to furthest O(n)), in buckets (possibly later with the time the neighbors have been in the routing table), alive/dead bool, key, peerid (missing peers observed in the Trie)\n",
    "A list of peers should be easy to iterate on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bbeebc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Peer:\n",
    "    \n",
    "    def __init__(self, key, neighbors):\n",
    "        self.key = key\n",
    "\n",
    "    # returns peer_id associated with self.key\n",
    "    def peer_id(self) -> str:\n",
    "        pass\n",
    "    \n",
    "    def alive(self) -> bool:\n",
    "        return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "73cca81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrieNode:\n",
    "    \n",
    "    def __init__(self, key=\"\", parent=None, peer=None):\n",
    "        self.key = key\n",
    "        self.parent = parent\n",
    "        self.children = (None, None)\n",
    "        self.peer = peer\n",
    "        self.size = 0\n",
    "        \n",
    "    def compute_size(self) -> int:\n",
    "        size = 0\n",
    "        for i in range(len(self.children)):\n",
    "            if self.children[i] is not None:\n",
    "                size+=self.children[i]\n",
    "        self.size = size\n",
    "        \n",
    "    def add(self, peer) -> bool:\n",
    "        if self.children[peer.key[len(self.key)]] is not None:\n",
    "            # child already exists, go down the branch\n",
    "            child = self.children[peer.key[len(self.key)]]\n",
    "            if peer.key[:len(child.key)] == child.key:\n",
    "                if len(peer.key) == len(child.key):\n",
    "                    # child == peer, we cannot insert peer in the trie\n",
    "                    return False\n",
    "                else:\n",
    "                    # peer should be a child of child\n",
    "                    success = child.add(peer)\n",
    "            else:\n",
    "                # skip\n",
    "                pass\n",
    "            # not exactly, we have to check the depth of the next level\n",
    "            # xor peer.key with children[1].key to decide where to fork\n",
    "            # TODO\n",
    "        else:\n",
    "            # leaf\n",
    "            pass\n",
    "        \n",
    "        if success:\n",
    "            self.size += 1\n",
    "        \n",
    "        return success\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9084fc8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "trie = Trie()\n",
    "for p in peers:\n",
    "    trie.add(p.key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8b0d1fe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31\n"
     ]
    }
   ],
   "source": [
    "print(max(trie.list_of_depths()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96b7a36",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
